---
title: "student-success-analysis"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("fastDummies")
library(rlang)
library(tidyverse)
library(styler)
styler::style_dir() # Style the current file so it's well formated
message("Your current working directory is: ", getwd())
```


## Data loading and getting the feeling of the dataset

```{r, colapse=TRUE}
students_org <- readxl::read_excel("student_data.xlsx")

# 370 rows, 39 columns
dim(students_org)

# Show column names
names(students_org)
```
```{r, colapse=TRUE}
# Show first few rows
head(students_org)
```


```{r, colapse=TRUE}
# Show details for each column
summary(students_org)
```


```{r, colapse=TRUE}
# Check the class of the column. "numeric", "character"...
sapply(students_org, class)
```

```{r, colapse=TRUE}

# Let's check if any columns exceed the maximum or minumum values specified in the pdf
# This makes sense only for numerical values

colMax <- students_org %>%
  select(where(is.numeric)) %>%
  sapply(., max, na.rm = TRUE)
colMax

# Every column has normal maximum value
```




```{r, colapse=TRUE}
# Are there any na values?
students_org %>% filter(is.na(.))
sum(apply(students_org, 2, is.nan))
students_org %>% filter(is.null(.))

# Drop these values just in case they show up with another dataset
# We will continue using "student" variable
students <- students_org %>% filter_all(all_vars(!is.na(.) & !is.nan(.) & !is.null(.)))
```

```{r, colapse=TRUE}
# Show average grade for all schools

schools <- students %>%
  select("school") %>%
  distinct(.)
schools # [GP, MS]
subject_final_grade_names <- names(students)[grepl("G3", names(students))]
subject_final_grade_names
students_final_grade <- students %>% select("school", subject_final_grade_names)

# Select only the subject grade and school
gp_mat <- students_final_grade %>%
  filter(school == "GP") %>%
  select(G3_mat, school)
gp_por <- students_final_grade %>%
  filter(school == "GP") %>%
  select(G3_por, school)
ms_mat <- students_final_grade %>%
  filter(school == "MS") %>%
  select(G3_mat, school)
ms_por <- students_final_grade %>%
  filter(school == "MS") %>%
  select(G3_por, school)

# Rename all columns to "grade"
gp_mat <- gp_mat %>% rename(grade = G3_mat)
gp_por <- gp_por %>% rename(grade = G3_por)
ms_mat <- ms_mat %>% rename(grade = G3_mat)
ms_por <- ms_por %>% rename(grade = G3_por)


# TODO: can this data be grouped and used dynamically? (support multiple schools and mutliple subjects)

# scale_this <- function(x){
#   (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
# }

# gp_mat_scaled <- gp_mat %>% mutate(G3_mat = scale_this(G3_mat))
# gp_por_scaled <- gp_por %>% mutate(G3_por = scale_this(G3_por))
# ms_mat_scaled <- ms_mat %>% mutate(G3_mat = scale_this(G3_mat))
# ms_por_scaled <- ms_por %>% mutate(G3_por = scale_this(G3_por))
```

```{r, colapse=TRUE}
# Plot math -- final grade
ggplot(gp_mat, aes(x = grade, y = (..count.. / sum(..count..)))) +
  geom_histogram(bins = 20, aes(color = school, fill = school), alpha = 0.5) +
  geom_histogram(data = ms_mat, bins = 20, aes(color = school, fill = school), alpha = 0.3) +
  geom_vline(data = gp_mat, aes(xintercept = mean(grade), color = school), linetype = "dashed") +
  geom_vline(data = ms_mat, aes(xintercept = mean(grade), color = school), linetype = "dashed") +
  xlab("Grade") +
  ylab("Relative frequency") +
  labs(title = "Mathematics - final grade for each school")

# Plot portug -- final grade
ggplot(gp_por, aes(x = grade, y = (..count.. / sum(..count..)))) +
  geom_histogram(bins = 20, aes(color = school, fill = school), alpha = 0.5) +
  geom_histogram(data = ms_por, bins = 20, aes(color = school, fill = school), alpha = 0.3) +
  geom_vline(data = gp_por, aes(xintercept = mean(grade), color = school), linetype = "dashed") +
  geom_vline(data = ms_por, aes(xintercept = mean(grade), color = school), linetype = "dashed") +
  xlab("Grade") +
  ylab("Relative frequency") +
  labs(title = "Portuguese - final grade for each school")
```

```{r, colapse=TRUE}
## Additional check for normailty is done with qqnorm
qqnorm(gp_mat$grade, pch = 1, frame = FALSE, main = "GP school math")
qqnorm(gp_por$grade, pch = 1, frame = FALSE, main = "GP school portuguese")
qqnorm(ms_mat$grade, pch = 1, frame = FALSE, main = "MS school math")
qqnorm(ms_por$grade, pch = 1, frame = FALSE, main = "MS school portuguese")
```


# F-test of variance equality
Argument order for F-test of variance equality doesn't matter but in general:
$$\frac{\sigma_{1}^2}{\sigma_{2}^2},\quad\sigma_{1}^2 > \sigma_{2}^2$$

$p \textemdash$ probability that under the null hypothesis of obtaining the value (of the test statistic) that's as extreme (or more extreme) than the value we got computed from the sample we have


If $p < \alpha$ we are rejecting the hypothesis $H0$ in favor of $H1$
  - falls under right tail => rejection

```{r, colapse=TRUE}

# Let's check variances just as a sanity check:
cat("Mathematics variances", var(gp_mat$grade), var(ms_mat$grade))
cat("Portugeuse variances", var(gp_por$grade), var(ms_por$grade))

# At first glance, it seems that we will probably reject H0 hypothesis for F-test in the case of Portuguese, as variances are vastly different.
alpha <- 0.05

# H0 - Variance of GP_MAT and MS_MAT are equal
# H1 - not H0
mat_f_test <- var.test(gp_mat$grade, ms_mat$grade, alternative = "two.sided") # F = 1.0752, p = 0.817
mat_f_test

# H0 - Variance of GP_POR and MS_MAT are equal
# H1 - not H0
por_f_test <- var.test(gp_por$grade, ms_por$grade, alternative = "two.sided") # F = 1.0752, p = 0.817
por_f_test
```

```{r, colapse=TRUE}
# This part won't be outputed as code in PDF

cat_reject_h0 <- function(prefix_message, is_h0_rejected) {
  cat(prefix_message, "\n")
  if (is_h0_rejected) cat("\tWe are rejecting the H0 hypothesis in favor of hypothesis H1\n") else cat("\tWe are not rejecting the H0 hypothesis\n")
}

var_equal_mat <- if (mat_f_test$p.value < alpha) FALSE else TRUE
cat_reject_h0("For mathemathics variance test:", !var_equal_mat)

var_equal_por <- if (por_f_test$p.value < alpha) FALSE else TRUE
cat_reject_h0("For Portuguese variance test:", !var_equal_por)
```

# T-test for grade equality
```{r, collapse=TRUE}
var_equal_mat
var_equal_por

# H0 - GP school has equal grades to in mathematics to MS (GP=MS)
# H1 - GP>MS
mat_t_test <- t.test(gp_mat$grade, ms_mat$grade, alt = "greater", var.equal = var_equal_mat)
is_gp_mat_better <- if (mat_t_test$p.value < alpha) TRUE else FALSE
cat_reject_h0("Mathemathics T-test test:", is_gp_mat_better)

# H0 - GP school has equal grades to in Portuguese to MS (GP=MS)
# H1 - GP>MS
por_t_test <- t.test(gp_por$grade, ms_por$grade, alt = "greater", var.equal = var_equal_por)
is_gp_por_better <- if (por_t_test$p.value < alpha) TRUE else FALSE
cat_reject_h0("Portuguese T-test test:", is_gp_por_better)
```

#Predviđanje uspjeha na kraju školske godine drugim varijablama iz skupa podataka

Transformirajmo kategoričke varijable u dummy varijable. 
```{r, collapse=TRUE}

require(fastDummies)
students_dummies=dummy_cols(students, remove_first_dummy = TRUE, remove_selected_columns = TRUE)

students_dummies

```
Sada provodimo individualne jednostavne linearne regresije G3_mat i G3_por  ovisno o svakoj od varijabli iz skupa, te spremamo $R^2$ vrijednosti i p-vrijednosti F-testova za jednostavnu linearnu regresiju u tablice $\text{modelsMat}$ i $\text{modelsPor}$
```{r, collapse=TRUE}
varName=c()
rSquaredM=c()
pValueofFM=c()
rSquaredP=c()
pValueofFP=c()

for(i in 1:ncol(students_dummies)){
  if(i!=18 && i!=21){
  colName=colnames(students_dummies)[i]
  names(students_dummies)[i]="tempx"
  
  modelMat=lm(formula=G3_mat~tempx, data=students_dummies)
  modelPor=lm(formula=G3_por~tempx, data=students_dummies)
  names(students_dummies)[i]=colName
  m=summary(modelMat)
  p=summary(modelPor)
  varName=append(varName,colName)
  rSquaredM=append(rSquaredM, m$r.squared)
  pValueofFM=append(pValueofFM,pf(m$fstatistic[1],m$fstatistic[2],m$fstatistic[3],lower.tail=FALSE) )
  rSquaredP=append(rSquaredP, p$r.squared)
  pValueofFP=append(pValueofFP,pf(p$fstatistic[1],p$fstatistic[2],p$fstatistic[3],lower.tail=FALSE) )
  }
  
  modelsMat=data.frame(varName, rSquaredM, pValueofFM)
  modelsPor=data.frame(varName, rSquaredP, pValueofFP)
}
```
##Predviđanje konačne ocjene iz matematike
Pogledajmo koje su se varijable ispostavile najboljim prediktorima za $\text{G3_mat}$ (poredano po $R^2$ vrijednostima)
```{R, collapse=TRUE}
 modelsMat[order(-modelsMat$rSquaredM), ]

```
Razmotrit ćemo prvih 10 najboljih prediktora. Najprije provjerimo jesu li neke od tih varijabli visoko korelirane:

```{r, collapse=TRUE}
cor(cbind(students_dummies$G2_mat,students_dummies$G1_mat,students_dummies$G2_por,students_dummies$G1_por,students_dummies$failures_mat,students_dummies$higher_yes,students_dummies$Medu,students_dummies$age,students_dummies$absences_por,students_dummies$Fedu ))
```
Kao i očekivano ocjene G2_mat i G1_mat visoko su korelirane, isto kao i G2_por i G1_por, a značajna je i korelacija između ocjena matematike i portugala. Osim toga uočimo koreliranost razina edukacije majke i oca.
```{r, collapse=TRUE}
cor(students_dummies$Medu, students_dummies$Fedu)
```
Zasad nećemo eliminirati nijedan regresor. Izgradimo linearni model od gore izdvojenih varijabli za G3_mat:

```{r, collapse=TRUE}
multiMat=lm(G3_mat~G2_mat + G1_mat + G2_por+ G1_por+ failures_mat + higher_yes+ Medu + age+ absences_por + Fedu, data=students_dummies )
summary(multiMat)

```
Pojednostavimo sad model, uzevši 5  varijabli s najnižim p-vrijednostima
```{r, collapse=TRUE}
multiMat2=lm(data=students_dummies, G3_mat~G2_mat+G1_mat+age+ failures_mat+G2_por)
summary(multiMat2)
```
Nešto nam se smanjio $R^2$, no prilagođeni $R^2$ se uvećao-indikacija da smo eliminirali neke nepotrebne regresore.

Dodatno pojednostavljenje modela smanjuje prilagođeni $R^2$
```{r, collapse=TRUE}
multiMat3=lm(data=students_dummies, G3_mat~G2_mat+G1_mat+age)
summary(multiMat3)
```

Provjerimo normalnost reziduala
```{r, collapse=True}
hist(rstandard(multiMat))
hist(rstandard(multiMat2))
qqnorm(rstandard(multiMat))
qqnorm(rstandard(multiMat2))
ks.test(rstandard(multiMat),'pnorm')
ks.test(rstandard(multiMat2),'pnorm')

```
Reziduali ne nalikuju normalnoj distribuciji.
Promotrimo ih u ovisnosti o predviđenoj vrijednosti.
```{r, collapse=TRUE}
plot(multiMat$fitted.values, multiMat$residuals)
plot(multiMat2$fitted.values, multiMat$residuals)
```
Zanimljivo je još i pogledati koliko dobro možemo predvidjeti konačnu ocjenu iz matematike bez ikakvog znanja o drugim ocjenama, oslanjajući se na ostalih 6 od 10 najboljih prediktora
```{r, collapse=TRUE}
bezOcjenaMat=lm(data=students_dummies, G3_mat~failures_mat + higher_yes + Medu + age + absences_por + Fedu )
summary(bezOcjenaMat)
```
Ovakav model objašnjava svega 18% varijance u promatranoj varijabli. Kao i očekivano same ocjene najbolji su prediktor konačne ocjene, ali  i neke druge varijable nisu potpuno irelevantne.

##Predviđanje konačne ocjene iz portugala
Pogledajmo koje su se varijable ispostavile najboljim prediktorima za $\text{G3_por}$ (poredano po $R^2$ vrijednostima)

```{r, collapse=TRUE}
modelsPor[order(-modelsPor$rSquaredP),]
```
Razmotrit ćemo prvih 13 najboljih prediktora. Najprije provjerimo jesu li neke od tih varijabli visoko korelirane:
```{r, collapse=TRUE}
cor(cbind(students_dummies$G2_por,students_dummies$G1_por,students_dummies$G1_mat,students_dummies$G2_mat,students_dummies$failures_mat,students_dummies$failures_por,students_dummies$higher_yes,students_dummies$Dalc,students_dummies$studytime,students_dummies$Walc, students_dummies$sex_M, students_dummies$Medu,students_dummies$address_U))
```
Otprije znamo za visoku koreiranost ocjena, a učimo još i visoku koreliranost razina konzumacija alkohola vikendom i radnim danima.
```{r, collapse=TRUE}
cor(students_dummies$Dalc, students_dummies$Walc)
```
Zasad ne odbacujući nijedan regresor izradimo linearni model za prethodno izdvojenih 13 varijabli.
```{r, collapse=TRUE}
multiPor=lm(data=students_dummies, G3_por~G2_por+G1_por+G1_mat+G2_mat+failures_mat+failures_por+higher_yes+Dalc+studytime+Walc+sex_M+Medu+address_U)
summary(multiPor)
```
Pojednostavimo sad uzevši 8 variabli s najnižim p-vrijednostima:
```{r, collapse=TRUE}
multiPor2=lm(data=students_dummies, G3_por~G2_por+ failures_por + G1_mat+G1_por+ G2_mat+address_U+sex_M+failures_mat)
summary(multiPor2)

```
Ovaj skup varijabli ispostavlja se daje najveći prilagođeni $R^2$:
```{r, collapse=TRUE}
#npr ograničavajući na 6 regresora smanjuje se prilagođeni R^2
multiPor3=lm(data=students_dummies, G3_por~G2_por+ failures_por + G1_mat+G1_por+ G2_mat+sex_M)
summary(multiPor3)
```
Provjerimo još normalnost reziduala:
```{r, collapse=TRUE}
hist(rstandard(multiPor))
hist(rstandard(multiPor2))
qqnorm(rstandard(multiPor))
qqnorm(rstandard(multiPor2))
ks.test(rstandard(multiPor),'pnorm')
ks.test(rstandard(multiPor2),'pnorm')

```
Reziduali nalikuju normalnoj distribuciji nešto više nego kod modela za konačnu ocjenu iz matematike, ali i dalje ne osobito.
Promotrimo ih u ovisnosti o predviđenoj vrijednosti.
```{r, collapse=TRUE}
plot(multiPor$fitted.values, multiPor$residuals)
plot(multiPor2$fitted.values, multiPor2$residuals)
```

Promotrimo još koliko dobro možemo predvidjeti konačnu ocjenu iz portugalskog bez znanja o drugim ocjenama, oslanjajući se na ostalih 9/13 najboljih prediktora:

```{r, collapse=TRUE}
bezOcjenaPor=lm(data=students_dummies, G3_por~failures_mat+failures_por+higher_yes+Dalc+studytime+Walc+sex_M+Medu+address_U)
summary(bezOcjenaPor)
```
Model bez ocjena za portugalski objašnjava skoro 30% varijance u promatranoj varijabli. Značajno poboljšanje u odnosu na model bez ocjena za matematiku.